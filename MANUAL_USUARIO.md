# üìñ Manual de Usuario - Gestor de Tablas ML

## Para ChatGPT: Gu√≠a de Ayuda al Usuario

Este manual est√° dise√±ado para que ChatGPT pueda ayudar al usuario a:
1. Generar datos apropiados para la aplicaci√≥n
2. Usar correctamente la aplicaci√≥n para visualizaci√≥n y entrenamiento de modelos
3. Entender el flujo de trabajo de miner√≠a de datos

---

## üéØ Prop√≥sito de la Aplicaci√≥n

La aplicaci√≥n **Gestor de Tablas - Machine Learning** es una herramienta web para:
- Cargar y editar datos tabulares (CSV, Excel)
- Visualizar relaciones entre variables
- Entrenar modelos de machine learning (regresi√≥n)
- Evaluar y guardar modelos entrenados

---

## üìä Estructura de Datos Recomendada

### Para Generar Datos con ChatGPT

Cuando el usuario pida generar datos, debes crear datasets con estas caracter√≠sticas:

1. **Formato**: CSV o Excel
2. **Columnas num√©ricas**: Al menos 2-3 columnas num√©ricas para caracter√≠sticas (X)
3. **Variable objetivo**: Una columna num√©rica que ser√° la variable a predecir (Y)
4. **Tama√±o**: M√≠nimo 50-100 filas para entrenamiento efectivo
5. **Datos realistas**: Valores coherentes y sin errores obvios

### Ejemplo de Estructura de Datos

```csv
id_cliente,edad,ingreso_mensual,visitas_pagina,compras_previas,compra_en_promo
1,56,763263,16,2,1
2,69,845155,15,3,0
3,46,1041202,16,5,1
...
```

**Caracter√≠sticas (X)**: `edad`, `ingreso_mensual`, `visitas_pagina`, `compras_previas`
**Variable Objetivo (Y)**: `compra_en_promo`

---

## üîÑ Flujo de Trabajo Correcto

### Paso 1: Cargar Datos
1. Usuario hace clic en "üìä Cargar Archivo"
2. Selecciona archivo CSV o Excel
3. La aplicaci√≥n autom√°ticamente:
   - Detecta tipos de datos
   - Trata valores faltantes
   - Ajusta outliers
   - Codifica variables categ√≥ricas

### Paso 2: Explorar y Editar Datos (Opcional)
- El usuario puede editar celdas directamente
- Agregar/eliminar filas o columnas
- Los cambios se guardan autom√°ticamente

### Paso 3: Seleccionar Variables para ML
En el panel derecho, secci√≥n "1Ô∏è‚É£ Selecci√≥n de Variables":

1. **Variable Objetivo (Y)**: 
   - Seleccionar la columna que se quiere predecir
   - Debe ser num√©rica
   - Ejemplo: `compra_en_promo`, `precio`, `ventas`

2. **Caracter√≠sticas (X)**:
   - Seleccionar las columnas que se usar√°n para predecir
   - Marcar con checkboxes las columnas relevantes
   - M√≠nimo 1 caracter√≠stica, recomendado 2-5
   - Ejemplo: `edad`, `ingreso_mensual`, `visitas_pagina`

### Paso 4: Visualizar Relaci√≥n (Autom√°tico)
- El gr√°fico se actualiza autom√°ticamente
- Muestra: Primera caracter√≠stica seleccionada (X) vs Variable objetivo (Y)
- El usuario puede cambiar el tipo de gr√°fico en la secci√≥n "2Ô∏è‚É£ Configuraci√≥n de Visualizaci√≥n"
- **Importante**: Esta visualizaci√≥n ayuda a entender si hay relaci√≥n entre las variables antes de entrenar

### Paso 5: Configurar y Entrenar Modelo
En la misma secci√≥n "1Ô∏è‚É£ Selecci√≥n de Variables":

1. **Algoritmo**: Seleccionar uno de los 8 algoritmos disponibles
   - **Regresi√≥n Lineal Simple**: Para una sola caracter√≠stica
   - **Regresi√≥n Lineal M√∫ltiple**: Para m√∫ltiples caracter√≠sticas
   - **Ridge/Lasso**: Para evitar sobreajuste
   - **Random Forest/Gradient Boosting**: Para relaciones no lineales
   - **XGBoost** ‚≠ê: **Recomendado** - Mejor rendimiento en la mayor√≠a de casos
   - **Decision Tree**: Para interpretabilidad

2. **Divisi√≥n Train/Test**: Ajustar el porcentaje de datos para test
   - Por defecto: 20% (80% train, 20% test)
   - Rango: 10% a 50% para test
   - Se muestra autom√°ticamente cu√°ntos datos van a cada conjunto
   - **Recomendaci√≥n**: 20% es est√°ndar, usar m√°s test (30%) si tienes muchos datos

3. **Normalizaci√≥n** (Opcional): Marcar checkbox si quieres normalizar datos
   - Aplica StandardScaler (media=0, desviaci√≥n=1)
   - √ötil cuando las caracter√≠sticas tienen escalas muy diferentes
   - **Recomendaci√≥n**: Usar si las caracter√≠sticas tienen rangos muy distintos (ej: edad 0-100 vs ingreso 0-1000000)

4. **Opciones Avanzadas** (Opcionales):
   - **Selecci√≥n autom√°tica de caracter√≠sticas**: Selecciona las mejores features (SelectKBest)
   - **Eliminar multicolinealidad**: Elimina caracter√≠sticas altamente correlacionadas (correlaci√≥n > 0.95)
   - **Caracter√≠sticas polinomiales**: Crea interacciones entre features (solo modelos lineales)
   - **Validaci√≥n cruzada**: Usa K-Fold para estimaci√≥n m√°s robusta del rendimiento

5. **Entrenar Modelo**: Clic en "üöÄ Entrenar Modelo"
   - El modelo se entrena con la divisi√≥n configurada
   - Se aplican las mejoras autom√°ticas seleccionadas
   - Se muestran m√©tricas autom√°ticamente
   - Se generan learning curves autom√°ticamente

### Paso 6: Ver Resultados y Validar Supuestos
Despu√©s del entrenamiento:

- **Learning Curves**: Se muestran autom√°ticamente en el gr√°fico (si hay suficientes datos)
  - Ayuda a detectar overfitting/underfitting visualmente
  - Si las curvas de train y test se separan mucho ‚Üí Overfitting
  - Si ambas son altas ‚Üí Underfitting

### Paso 7: Hacer Predicciones (Nuevo)
Despu√©s de entrenar un modelo, aparece autom√°ticamente el panel "üîÆ Predicci√≥n con Modelo":
1. Ingresar valores para cada caracter√≠stica usada en el modelo
2. Clic en "üîÆ Predecir"
3. Ver la predicci√≥n del modelo para la variable objetivo
- **M√©tricas** aparecen en la misma secci√≥n:
  - **R¬≤ Score (Train)**: Qu√© tan bien explica el modelo en datos de entrenamiento
  - **R¬≤ Score (Test)**: Qu√© tan bien explica el modelo en datos nuevos (M√ÅS IMPORTANTE)
  - **RMSE (Test)**: Error promedio en datos de prueba (m√°s bajo mejor)
  - **MAE (Test)**: Error absoluto promedio en datos de prueba (m√°s bajo mejor)
  - **Divisi√≥n de datos**: Muestra cantidad y porcentaje de datos en train y test

- **Validaci√≥n de Supuestos** (solo para regresi√≥n lineal):
  - **Test de Normalidad (Shapiro-Wilk)**: Verifica si los residuos siguen distribuci√≥n normal
    - "Normal" (p > 0.05): Los residuos son normales ‚úÖ
    - "No normal" (p ‚â§ 0.05): Los residuos no son normales ‚ö†Ô∏è
  - **Estad√≠sticas de residuos**: Media y desviaci√≥n est√°ndar
  - **Gr√°fico de residuos**: Marcar checkbox "Ver gr√°fico de residuos" para visualizar
    - Los residuos deben estar distribuidos aleatoriamente alrededor de 0
    - Si hay patrones (curvas, conos), el modelo no cumple supuestos

- **Gr√°fico** cambia autom√°ticamente a "Real vs Predicho" o muestra "Learning Curves"
  - **Learning Curves**: Muestra c√≥mo el error cambia con el tama√±o de entrenamiento
    - Si las curvas se separan mucho ‚Üí Overfitting (sobreajuste)
    - Si ambas curvas son altas ‚Üí Underfitting (subajuste)
    - Si ambas convergen y son bajas ‚Üí Buen ajuste
- **Panel de Predicci√≥n**: Aparece autom√°ticamente despu√©s del entrenamiento
  - Permite ingresar valores para las caracter√≠sticas
  - Obtiene predicci√≥n instant√°nea del modelo entrenado
- El modelo se guarda autom√°ticamente en SQLite

---

## üé® Tipos de Gr√°ficos Disponibles

1. **üìä Dispersi√≥n**: Para ver correlaci√≥n entre dos variables
2. **üìà L√≠nea**: Para tendencias temporales o secuenciales
3. **üìä Barras**: Para comparar categor√≠as
4. **üìâ √Årea**: Similar a l√≠nea con √°rea rellena
5. **ü•ß Pastel**: Para proporciones
6. **üîÄ Combinado**: Combina √°rea, barras y l√≠nea
7. **üï∏Ô∏è Radar**: Para m√∫ltiples variables
8. **üó∫Ô∏è Treemap**: Visualizaci√≥n jer√°rquica

**Recomendaci√≥n**: Usar **Dispersi√≥n** o **L√≠nea** para an√°lisis de regresi√≥n.

---

## üí° Consejos para ChatGPT al Ayudar al Usuario

### Al Generar Datos:
1. **Pregunta el contexto**: ¬øQu√© quiere predecir? ¬øQu√© variables tiene disponibles?
2. **Genera datos realistas**: Valores coherentes con el dominio
3. **Incluye variabilidad**: No todos los valores iguales
4. **Asegura relaci√≥n**: Si es para ML, las caracter√≠sticas deben tener alguna relaci√≥n con el target
5. **Formato correcto**: CSV con encabezados, valores num√©ricos donde corresponde

### Al Explicar el Uso:
1. **Enfatiza el flujo**: Variables ‚Üí Visualizar ‚Üí Entrenar
2. **Explica las m√©tricas**: Qu√© significa R¬≤, RMSE, MAE
3. **Sugiere algoritmos**: Seg√∫n el tipo de problema
4. **Interpreta gr√°ficos**: Ayuda a entender qu√© muestra cada gr√°fico
5. **Valida selecci√≥n**: Verifica que las variables seleccionadas tengan sentido

### Al Interpretar Resultados:
1. **R¬≤ Score (Test) > 0.7**: Buen modelo
2. **R¬≤ Score (Test) 0.5-0.7**: Modelo aceptable
3. **R¬≤ Score (Test) < 0.5**: Modelo pobre, revisar variables
4. **Compara Train vs Test**: Si R¬≤ Train >> R¬≤ Test, hay sobreajuste
5. **Compara algoritmos**: Sugiere probar diferentes algoritmos
6. **Revisa el gr√°fico**: Si Real vs Predicho est√° disperso, el modelo no es bueno
7. **Validaci√≥n de supuestos**: Para regresi√≥n lineal, verificar normalidad de residuos
   - Si no son normales, considerar transformaciones o algoritmos no lineales

---

## üîç Ejemplos de Uso

### Ejemplo 1: Predicci√≥n de Ventas
**Variables**:
- Caracter√≠sticas (X): `publicidad`, `precio`, `temporada`
- Objetivo (Y): `ventas`

**Flujo**:
1. Cargar datos con estas columnas
2. Seleccionar `ventas` como objetivo
3. Seleccionar `publicidad`, `precio`, `temporada` como caracter√≠sticas
4. Visualizar relaci√≥n (autom√°tico)
5. Configurar divisi√≥n Train/Test (20% por defecto)
6. Decidir si normalizar (si las escalas son muy diferentes)
7. Entrenar con "Regresi√≥n Lineal M√∫ltiple"
8. Ver m√©tricas (Train y Test), validaci√≥n de supuestos
9. Ver gr√°fico Real vs Predicho y opcionalmente gr√°fico de residuos

### Ejemplo 2: Predicci√≥n de Precio
**Variables**:
- Caracter√≠sticas (X): `metros_cuadrados`, `habitaciones`, `a√±os_construccion`
- Objetivo (Y): `precio`

**Flujo**:
1. Cargar datos inmobiliarios
2. Seleccionar `precio` como objetivo
3. Seleccionar caracter√≠sticas relevantes
4. Visualizar relaci√≥n
5. Configurar divisi√≥n Train/Test
6. Considerar normalizaci√≥n (precios y metros pueden tener escalas diferentes)
7. Entrenar con "Random Forest" (mejor para relaciones no lineales)
8. Evaluar resultados: m√©tricas, validaci√≥n de supuestos (si aplica)
9. Comparar con otros algoritmos si es necesario

---

## ‚ö†Ô∏è Errores Comunes y Soluciones

### Error: "Seleccione variable objetivo y al menos una caracter√≠stica"
**Soluci√≥n**: Asegurar que se seleccion√≥:
- Una variable objetivo (Y)
- Al menos una caracter√≠stica (X) marcada

### Error: "No hay datos v√°lidos despu√©s de la limpieza"
**Soluci√≥n**: 
- Verificar que las columnas seleccionadas tengan datos num√©ricos
- Revisar que no todas las filas tengan valores faltantes

### Gr√°fico vac√≠o
**Soluci√≥n**:
- Verificar que se seleccionaron caracter√≠sticas y variable objetivo
- Asegurar que los datos tienen valores num√©ricos v√°lidos

### R¬≤ Score muy bajo (< 0.3)
**Soluci√≥n**:
- Las caracter√≠sticas seleccionadas pueden no tener relaci√≥n con el objetivo
- Probar diferentes caracter√≠sticas
- Considerar transformaciones de datos
- Probar algoritmos m√°s complejos (Random Forest, Gradient Boosting)

---

## üìö Conceptos Clave para Explicar

### Variable Objetivo (Y)
- Es lo que queremos predecir
- Debe ser num√©rica para regresi√≥n
- Ejemplos: precio, ventas, temperatura, tiempo

### Caracter√≠sticas (X)
- Son las variables que usamos para predecir
- Pueden ser m√∫ltiples
- Deben tener relaci√≥n con el objetivo
- Ejemplos: edad, ingresos, tama√±o, ubicaci√≥n

### R¬≤ Score
- Mide qu√© tan bien el modelo explica la variabilidad
- Rango: 0 a 1 (o negativo si es muy malo)
- 1.0 = perfecto, 0.0 = no explica nada
- > 0.7 = bueno, > 0.5 = aceptable

### Train/Test Split
- Configurable: 10% a 50% para test (por defecto 20%)
- Evita sobreajuste
- Las m√©tricas de "Test" son las importantes
- Si R¬≤ Train >> R¬≤ Test, hay sobreajuste (overfitting)

### Normalizaci√≥n
- StandardScaler: Escala datos a media 0 y desviaci√≥n est√°ndar 1
- √ötil cuando caracter√≠sticas tienen escalas muy diferentes
- No siempre es necesario, depende del algoritmo y datos

### Validaci√≥n de Supuestos (Regresi√≥n Lineal)
- **Normalidad de residuos**: Test de Shapiro-Wilk
  - p > 0.05: Residuos normales ‚úÖ
  - p ‚â§ 0.05: Residuos no normales ‚ö†Ô∏è
- **Gr√°fico de residuos**: Debe mostrar distribuci√≥n aleatoria alrededor de 0
- Si no se cumplen supuestos, considerar:
  - Transformaciones de datos
  - Algoritmos no lineales (Random Forest, Gradient Boosting)

---

## üéì Gu√≠a para ChatGPT: Preguntas Frecuentes

### "¬øQu√© datos necesito?"
- Datos tabulares (CSV/Excel)
- Al menos 50-100 filas
- Columnas num√©ricas para caracter√≠sticas y objetivo
- Datos realistas y coherentes

### "¬øQu√© algoritmo elegir?"
- **XGBoost** ‚≠ê: **Recomendado** - Mejor rendimiento en la mayor√≠a de casos, maneja relaciones no lineales
- **Regresi√≥n Lineal M√∫ltiple**: Para empezar, relaciones lineales, interpretable
- **Ridge/Lasso**: Si hay muchas caracter√≠sticas, evitar sobreajuste
- **Random Forest/Gradient Boosting**: Si la relaci√≥n no es lineal, robusto
- **Decision Tree**: Si necesitas interpretabilidad m√°xima

### "¬øPor qu√© mi modelo tiene R¬≤ bajo?"
- Las caracter√≠sticas no tienen relaci√≥n con el objetivo
- Necesitas m√°s datos
- Necesitas diferentes caracter√≠sticas
- La relaci√≥n no es lineal (probar Random Forest)

### "¬øC√≥mo interpreto el gr√°fico Real vs Predicho?"
- Si los puntos est√°n cerca de la l√≠nea diagonal = buen modelo
- Si est√°n dispersos = mal modelo
- Si hay patrones = el modelo no captura algo importante

### "¬øCu√°ndo usar normalizaci√≥n?"
- Cuando las caracter√≠sticas tienen escalas muy diferentes (ej: edad 0-100 vs ingreso 0-1000000)
- Generalmente √∫til para regresi√≥n lineal
- Random Forest y Decision Tree no necesitan normalizaci√≥n
- Si no est√°s seguro, prueba con y sin normalizaci√≥n

### "¬øQu√© porcentaje usar para test?"
- **20% (por defecto)**: Est√°ndar, funciona bien en la mayor√≠a de casos
- **30%**: Si tienes muchos datos (>1000 filas) y quieres m√°s confianza
- **10-15%**: Si tienes pocos datos (<200 filas) y necesitas m√°s para entrenar
- **No usar >50%**: Dejas muy poco para entrenar

### "¬øQu√© significa que los residuos no sean normales?"
- Los residuos deber√≠an seguir una distribuci√≥n normal para regresi√≥n lineal
- Si no son normales (p ‚â§ 0.05), el modelo puede tener sesgos
- Soluciones:
  - Transformar la variable objetivo (log, sqrt)
  - Usar algoritmos no lineales (Random Forest, Gradient Boosting)
  - Revisar si hay outliers o datos err√≥neos

### "¬øC√≥mo interpreto el gr√°fico de residuos?"
- **Bien**: Residuos distribuidos aleatoriamente alrededor de 0, sin patrones
- **Mal**: 
  - Patr√≥n de embudo: Varianza no constante (heterocedasticidad)
  - Curva: Relaci√≥n no lineal no capturada
  - Tendencia: El modelo no captura algo importante

---

## üÜï Nuevas Funcionalidades

### XGBoost - Algoritmo Recomendado
- **XGBoost** es ahora el algoritmo recomendado (marcado con ‚≠ê)
- Generalmente proporciona mejor rendimiento que otros algoritmos
- Maneja relaciones no lineales de forma efectiva
- Hiperpar√°metros optimizados autom√°ticamente seg√∫n el tama√±o de datos

### Learning Curves (Curvas de Aprendizaje)
- Se generan autom√°ticamente despu√©s del entrenamiento (si hay suficientes datos)
- Muestran c√≥mo el error cambia con el tama√±o del conjunto de entrenamiento
- **Interpretaci√≥n**:
  - Curvas que convergen y son bajas ‚Üí Buen modelo
  - Curvas que se separan mucho ‚Üí Overfitting (sobreajuste)
  - Ambas curvas altas ‚Üí Underfitting (subajuste)
- Ayuda a diagnosticar problemas del modelo visualmente

### Predicci√≥n de Nuevos Valores
- Panel interactivo que aparece autom√°ticamente despu√©s de entrenar
- Permite ingresar valores para las caracter√≠sticas del modelo
- Obtiene predicci√≥n instant√°nea de la variable objetivo
- √ötil para usar el modelo entrenado en producci√≥n

### Mejoras Autom√°ticas Avanzadas
- **Eliminaci√≥n de multicolinealidad**: Elimina caracter√≠sticas altamente correlacionadas (correlaci√≥n > 0.95)
- **Selecci√≥n autom√°tica de caracter√≠sticas**: Selecciona las mejores features (SelectKBest)
- **Variables derivadas**: Crea autom√°ticamente nuevas features (multiplicaciones, divisiones, cuadrados, ratios)
- **Transformaciones logar√≠tmicas**: Aplica log a variables altamente sesgadas
- **Caracter√≠sticas polinomiales**: Crea interacciones entre features (solo modelos lineales)
- **Validaci√≥n cruzada**: Opci√≥n para K-Fold cross-validation

### Comparaci√≥n de Modelos
- El endpoint `/api/models` ahora incluye m√©tricas completas
- Permite comparar m√∫ltiples modelos entrenados
- Ordenamiento autom√°tico por R¬≤ test (mejor primero)

## üîß Funcionalidades T√©cnicas

### Preprocesamiento Autom√°tico
- **Duplicados**: Se eliminan autom√°ticamente al cargar
- **Valores faltantes**: Se rellenan con mediana (num√©ricos) o moda (categ√≥ricos)
- **Outliers**: Se ajustan (no se eliminan) usando m√©todo IQR
- **Infinitos**: Se eliminan y rellenan
- **Categ√≥ricas**: Se codifican autom√°ticamente con LabelEncoder
- **Variables derivadas**: Se crean autom√°ticamente (multiplicaciones, divisiones, cuadrados, ratios)
- **Transformaciones logar√≠tmicas**: Se aplican a variables altamente sesgadas (skewness > 1.5)

### Preprocesamiento Manual (Opcional)
- **Normalizaci√≥n**: Opci√≥n para aplicar StandardScaler antes del entrenamiento
- **Divisi√≥n Train/Test**: Configurable entre 10% y 50% para test
- **Edici√≥n de datos**: CRUD completo en la tabla antes del entrenamiento
- **Selecci√≥n de caracter√≠sticas**: Opci√≥n para selecci√≥n autom√°tica (SelectKBest)
- **Eliminaci√≥n de multicolinealidad**: Opci√≥n para eliminar features correlacionadas (correlaci√≥n > 0.95)
- **Caracter√≠sticas polinomiales**: Opci√≥n para crear interacciones (solo modelos lineales)
- **Validaci√≥n cruzada**: Opci√≥n para usar K-Fold cross-validation

### Guardado de Modelos
- Se guardan en SQLite (`backend/modelos.db`)
- Incluyen: algoritmo, m√©tricas (train y test), caracter√≠sticas, modelo serializado
- Incluyen: informaci√≥n de divisi√≥n de datos, estad√≠sticas de residuos
- Incluyen: learning curves, feature importance, mejoras aplicadas
- Se pueden usar para hacer predicciones despu√©s
- Se pueden comparar con otros modelos entrenados

### Actualizaci√≥n Autom√°tica
- El gr√°fico se actualiza cuando cambias variables
- No necesitas recargar la p√°gina
- Los cambios en la tabla se reflejan inmediatamente
- Las learning curves se generan autom√°ticamente despu√©s del entrenamiento
- El panel de predicci√≥n aparece autom√°ticamente despu√©s de entrenar

---

## üíª Compatibilidad con Windows

La aplicaci√≥n **funciona perfectamente en Windows**. 

### Inicio en Windows:
1. **Opci√≥n 1 (Recomendada)**: Hacer doble clic en `start.bat`
2. **Opci√≥n 2**: Abrir PowerShell o CMD en la carpeta del proyecto y ejecutar:
   ```cmd
   start.bat
   ```

### Diferencias con Linux/Mac:
- En Windows, el script `start.bat` abre ventanas separadas para backend y frontend
- Los comandos de Python son los mismos (`python` en lugar de `python3`)
- La activaci√≥n del entorno virtual es: `venv\Scripts\activate` (en lugar de `source venv/bin/activate`)

### Requisitos en Windows:
- Python 3.8+ instalado (descargar desde python.org)
- Node.js 16+ instalado (descargar desde nodejs.org)
- Asegurarse de marcar "Add Python to PATH" durante la instalaci√≥n

## üìû Soporte

Si el usuario tiene problemas:
1. Verificar que el backend est√© corriendo (http://localhost:8000)
2. Verificar que el frontend est√© corriendo (http://localhost:3000)
3. Revisar la consola del navegador (F12) para errores
4. Verificar que los datos tengan el formato correcto
5. **En Windows**: Verificar que las ventanas de backend y frontend est√©n abiertas

---

**Nota para ChatGPT**: Usa este manual para guiar al usuario paso a paso, generar datos apropiados seg√∫n su necesidad, y ayudarle a interpretar los resultados de manera profesional.
